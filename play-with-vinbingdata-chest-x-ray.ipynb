{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Plot the histogram distribution graphs together\n# classes = train.class_name.unique() contains the names of different classes \nfig, axs = plt.subplots(3, 4, figsize = (15, 20)) # 5 rows and 3 columns\nfig.subplots_adjust(hspace = .1, wspace = .1)\naxs = axs.ravel()\nfig = plt.figure(figsize=(15,3))\nfig.subplots_adjust(hspace = .1, wspace = .1)\nfig.suptitle(\"Histogram Distribution\")\nn = 0\nfor i in range(3):\n    fig = plt.figure(figsize=(15,3))\n    fig.subplots_adjust(hspace = .1, wspace = .1)\n    fig.suptitle(\"Histogram Distribution\")\n    for j in range(4):\n        n += 1\n        fig.add_subplot(i+1, j+1, i+1)\n        plt.plot(DrawGauss(n))\n        plt.title(classes[n])\n    plt.show()\n    \n#plt.show()"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# This snippet of code is from \n# https://stackoverflow.com/questions/19695249/load-just-part-of-an-image-in-python/19772446#19772446\n# Since it contains the usage of Pool, I keep the link for future use.\n#import time\n\"\"\"\nfrom PIL import Image\nfrom multiprocessing import Pool\n\n# crop out the part of the whole image to process further analysis\ndef crop_image(dir, edge):\n    im = Image.open(dir)\n    w,h = im.size\n    imc = im.crop(w-edge[3], h-edge[2], w-edge[1], h-edge[0])\n    return np.array(imc)\n \"\"\"   "},{"metadata":{},"cell_type":"markdown","source":"\n## Notebooks and webpages I referenced\n[VinBigData - Crop and Resize X-Ray Images](https://www.kaggle.com/anhlv2312/vinbigdata-crop-and-resize-x-ray-images)\n\nThe procedure of cropping is not necessary in my opinion. However, the idea of using **brightness scale** is a good idea to me. I may use that in the future code.\n\n[Creating WHL file - Retinanet](https://www.kaggle.com/akhileshdkapse/creating-whl-file-retinanet). This one tells how to use RetinalNet to do the classification job.\n\n[Visual In-Depth EDA – VinBigData Competition Data](https://www.kaggle.com/dschettler8845/visual-in-depth-eda-vinbigdata-competition-data) Heat map is one of the attracting point in this notebook. I can learn how to draw sub-plot from here\n\n[Localization of Findings](https://www.kaggle.com/craigmthomas/localization-of-findings) Another notebook about heatmap. I can learn more skills on sub_plot from this notebook.\n\n[VBD EfficientDET TF2 Object Detection API](https://www.kaggle.com/sreevishnudamodaran/vbd-efficientdet-tf2-object-detection-api) TensorFlow 2 Object Detection API is a framework built on top of TF2, which makes it easy to construct, train and deploy, robust and high performance Object Detection Models. \n\n[(Python) utility to convert medical images to jpg and png](https://pypi.org/project/med2image/) This a link, descriping the usage of med2image 2.2.10\n\n[Pandas dataframe filter with Multiple conditions](https://kanoki.org/2020/01/21/pandas-dataframe-filter-with-multiple-conditions/)\n\n[Pandas how to get a cell value and update it](https://kanoki.org/2019/04/12/pandas-how-to-get-a-cell-value-and-update-it/)\n\n[Fitter used to find out the best fitting function](https://pypi.org/project/fitter/)\n\n[Applying lambda functions to pandas dataframe](https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/)\n\n[Fitting a 2D gaussian](https://scipy-cookbook.readthedocs.io/items/FittingData.html)\n\n[Plot 2-D Histogram in Python using Matplotlib](https://www.geeksforgeeks.org/plot-2-d-histogram-in-python-using-matplotlib/)\n\n[Creating a 2d histogram from a numpy matrix](https://stackoverflow.com/questions/27156381/python-creating-a-2d-histogram-from-a-numpy-matrix)\n\n[How to get weighted random choice in Python?](https://www.geeksforgeeks.org/how-to-get-weighted-random-choice-in-python/)\n\n[Reorder pandas dataframe columns](https://www.datasciencemadesimple.com/re-arrange-or-re-order-the-column-of-dataframe-in-pandas-python-2/)\nThe next page is about reordering rows in a dataframe"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n \n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install mahotas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import mahotas as mh\nimport pandas as pd\nfrom fastai.medical.imaging import *\nfrom fastai.vision.all import *\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport pydicom # https://pydicom.github.io/ dealing with Dicom (Digital Imaging in Medicine)\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom scipy.optimize import curve_fit\nfrom random import randint\nfrom pylab import gray, imshow, show\nimport seaborn as sns\nimport plotly.offline as py\nimport plotly.graph_objs as go\nimport warnings\nwarnings.filterwarnings(\"ignore\", message=\"The (0028,0101) 'Bits Stored' value (12-bit) doesn't match the JPEG 2000 data (16-bit).\")\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset_dir = '../input/vinbigdata-chest-xray-abnormalities-detection'\nmy_dataset = '../input/withhf'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dicom2array(path, voi_lut=True, fix_monochrome=True):\n    dicom = pydicom.read_file(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title=\"\", cmap='gray', img_size=(500,500)):\n    rows = len(imgs)//cols + 1\n    fig = plt.figure(figsize=(cols*size, rows*size))\n    for i, img in enumerate(imgs):\n        if img_size is not None:\n            img = cv2.resize(img, img_size)\n        fig.add_subplot(rows, cols, i+1)\n        plt.imshow(img, cmap=cmap)\n    plt.suptitle(title)\n    #plt.savefig('temp.png')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_area(row):\n    return (row['x_max'] - row['x_min']) * (row['y_max'] - row['y_min'])\ndef center_x(row):\n    return (row['x_max'] + row['x_min']) / 2\ndef center_y(row):\n    return (row['y_max'] + row['y_min']) / 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_center(num):\n    studyClasses = train[train.class_name == classes[num]]\n    studyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\n    plt.figure(figsize=(8,8))\n    center = pd.DataFrame()\n    center['center_x'] = studyClasses.apply(center_x, axis = 1)\n    center['center_y'] = studyClasses.apply(center_y, axis = 1)\n    #plt.figure(figsize=(14,6))\n    plt.title(classes[num])\n    plt.scatter(center.center_x, center.center_y)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install fitter","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from fitter import Fitter","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/vinbigdata-chest-xray-abnormalities-detection/train.csv')\ntrain.head()\n#train.loc[: , ['class_name', 'class_id']]\n#train.loc[0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[50:80 , ['image_id', 'class_name', 'class_id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['image_id'].str.contains(\"3a4407a2df891526e94ba4541023f49\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dfObj[dfObj['x_min']> 1300]\ndfObj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfData[53,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = train.class_name.unique()\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"studyClasses = train[train.class_name == 'Pleural effusion']\ncenter = pd.DataFrame()\ncenter['center_x'] = studyClasses.apply(center_x, axis = 1)\ncenter['center_y'] = studyClasses.apply(center_y, axis = 1)\nx = center.center_x\nx_min = x.min()\nx_max = x.max()\nprint(\"x_min, x_max: \", x_min, x_max)\n\ny = center.center_y\ny_min = y.min()\ny_max = y.max()\nprint(\"y_min, y_max: \", y_min, y_max)\n\n\nx_bins = np.linspace(x_min, x_max, 40) \ny_bins = np.linspace(y_min, y_max, 40)\n\n\nfig, ax = plt.subplots(figsize =(10, 7)) \n# Creating plot \nplt.hist2d(x, y, bins =[x_bins, y_bins]) \nplt.title(\"Changing the bin scale\")\n\nax.set_xlabel('X-axis')  \nax.set_ylabel('Y-axis') \n\nplt.show() "},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_id == 8]\ncenter = pd.DataFrame()\ncenter['center_x'] = studyClasses.apply(center_x, axis = 1)\ncenter['center_y'] = studyClasses.apply(center_y, axis = 1)\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\nx = center.center_x\nx_min = x.min()\nx_max = x.max()\n\ny = center.center_y\ny_min = y.min()\ny_max = y.max()\n\nz = studyClasses.boxArea\n\ncut = 21\nxedges, yedges = np.linspace(x_min, x_max, cut), np.linspace(y_min,  y_max, cut)\nhist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))\nxidx = np.clip(np.digitize(x, xedges), 0, hist.shape[0]-1)\nyidx = np.clip(np.digitize(y, yedges), 0, hist.shape[1]-1)\nc = hist[xidx, yidx]\nplt.scatter(x, y, c=c)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob = hist/hist.sum()\nweight = prob.flatten()\nconsecut = np.arange(0, len(weight))\n\nselect = int(np.count_nonzero(hist.flatten())*0.618)\n#select = 100\nrandomNumberList = np.random.choice(consecut, select, p=weight) \n\"\"\"\nprint(randomNumberList)\nprint(weight[randomNumberList[5]])\nxx = randomNumberList[5]//(cut - 1)\nyy = randomNumberList[5] % (cut - 1)\nprint(prob[xx, yy])\nprint(xedges[cut-1])\nprint(yedges[cut-1])\n#print(x_min, x_max)\ntemp = 0\ntemp_st_x = []\ntemp_st_y = []\ntemp_en_x = []\ntemp_en_y = []\nfor c, d, st_x, st_y, en_x, en_y in zip(x, y, studyClasses.x_min, studyClasses.y_min, studyClasses.x_max, studyClasses.y_max):\n    if ((c > xedges[xx]) & (c < xedges[xx+1])) & ((d > yedges[yy]) & (d < yedges[yy+1])):\n        temp_st_x.append(st_x)\n        temp_st_y.append(st_y)\n        temp_en_x.append(en_x)\n        temp_en_y.append(en_y)\n        temp += 1\nprint(temp)  \nprint(temp_st_x)\n\"\"\"\n# I decide to use the average value to present the value of the selected samples in a grid\n#aver_x_min = np.mean(temp_st_x)\n#aver_y_min = np.mean(temp_st_y)\n#aver_x_max = np.mean(temp_en_x)\n#aver_y_max = np.mean(temp_en_y)\naver_x_min = []\naver_y_min = []\naver_x_max = []\naver_y_max = []\nfor element in randomNumberList:\n    xx = element//(cut - 1)\n    yy = element % (cut - 1)\n    temp_st_x = []\n    temp_st_y = []\n    temp_en_x = []\n    temp_en_y = []\n    for c, d, st_x, st_y, en_x, en_y in zip(x, y, studyClasses.x_min, studyClasses.y_min, studyClasses.x_max, studyClasses.y_max):\n        if ((c > xedges[xx]) & (c < xedges[xx+1])) & ((d > yedges[yy]) & (d < yedges[yy+1])):\n            temp_st_x.append(st_x)\n            temp_st_y.append(st_y)\n            temp_en_x.append(en_x)\n            temp_en_y.append(en_y)\n    aver_x_min.append(np.mean(temp_st_x))\n    aver_y_min.append(np.mean(temp_st_y))\n    aver_x_max.append(np.mean(temp_en_x))\n    aver_y_max.append(np.mean(temp_en_y))\n    \n#print(aver_x_min)\nprint(len(aver_x_min))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following function is adapted from the function getHF_each_box\n# For each img, the function will return a DataFrame for testing\n#dfObj = pd.DataFrame()\ndef getHF_each_image(row):\n    #dfObj = pd.DataFrame(columns=row.columns.values)\n    imgT = []\n    #print(row['image_id'])\n    img_id = str(row['image_id'])\n    img_path = f'{dataset_dir}/train/{img_id}.dicom'\n    img_path = '../input/vinbigdata-chest-xray-abnormalities-detection/test/83caa8a85e03606cf57e49147d7ac569.dicom'\n    imgT = dicom2array(path=img_path)\n    imgT = np.stack([imgT, imgT, imgT], axis=-1)\n    #box = row.loc[['x_min', 'y_min', 'x_max', 'y_max']].values\n    #print(box.shape)\n    #img = imgT[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n    #meanValue = mh.features.haralick(img).mean(0)\n    #get.loc[row.name,['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13']] = meanValue\n    i = 0\n    for x_min, y_min, x_max, y_max in zip(aver_x_min, aver_y_min, aver_x_max, aver_y_max):\n        img = imgT[int(x_min):int(x_max), int(y_min):int(y_max)]\n        try:\n            meanValue = mh.features.haralick(img).mean(0)\n            dfObj.loc[row.name+i,['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13']] = meanValue\n            dfObj.loc[row.name+i,['image_id','x_min', 'y_min', 'x_max', 'y_max']] = row.image_id, x_min, y_min, x_max, y_max\n            i += 1\n        except:\n            print(\"Some issue happens on mahotas\")\n            pass\n    return dfObj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following lines of codes are making use of \nT1 = time.time()\ndfObj = pd.DataFrame(columns=train.columns.values)\ndfObj = getHF_each_image(train.loc[56,:])\nT2 = time.time()\nprint (\"Time used: \", T2 - T1)\ndfObj","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dfObj.loc[59:72,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_HF[train_HF['image_id'].str.contains(\"d106ec9b305178f3da060efe3191499a\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxArea3d(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#According to different given number i, the returned DataFrame will give training data with binary label\ntrain_HF = pd.read_csv('../input/withhf/FoundSthWithHF.csv')\ndef returnTrainData(i):\n    trainData = pd.DataFrame()\n    trainData = train_HF\n    trainData['chk'] = train_HF.apply(lambda n: 1 if n['class_id'] == i else 0, axis = 1)\n    \n    #trainData['boxArea'] = train_7.apply(get_area, axis = 1)   \n    #trainData['xCenter'] = train_7.apply(center_x, axis = 1)\n    #trainData['yCenter'] = train_7.apply(center_y, axis = 1)\n    \n    return trainData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_1['chk'] = train_1.apply(lambda n: 1 if n['class_id'] == 1 else 0, axis = 1)\ntrain_1['boxArea'] = train_1.apply(get_area, axis = 1)   # for now, I will keep those three features so that I can compare current result with previous one\ntrain_1['xCenter'] = train_1.apply(center_x, axis = 1)\ntrain_1['yCenter'] = train_1.apply(center_y, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_2['chk'] = train_2.apply(lambda n: 1 if n['class_id'] == 2 else 0, axis = 1)\ntrain_2['boxArea'] = train_1.apply(get_area, axis = 1)   # for now, I will keep those three features so that I can compare current result with previous one\ntrain_2['xCenter'] = train_1.apply(center_x, axis = 1)\ntrain_2['yCenter'] = train_1.apply(center_y, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_13.loc[65:85, ['class_id', 'chk']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#features = ['x_min', 'y_min', 'x_max', 'y_max', 'HF1', 'HF2', 'HF3', 'HF4',\n#       'HF5', 'HF6', 'HF7', 'HF8', 'HF9', 'HF10', 'HF11', 'HF12', 'HF13', 'boxArea', 'xCenter', 'yCenter']\nfeatures = ['HF1', 'HF2', 'HF3', 'HF4', 'HF5', 'HF6', 'HF7', 'HF8', 'HF9', 'HF10', 'HF11', 'HF12', 'HF13']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the given data into features and target, so that we can standardize features and further performing PCA upon those features\ninputData = pd.DataFrame()\ninputData = returnTrainData(8)\n#x = train_0.loc[:, features].values\nx = inputData.loc[:, features].values\n#y = train_0.loc[:, 'chk'].values\ny = inputData.loc[:, 'chk'].values\n\n#x = StandardScaler().fit_transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(.98)\npca.fit(x)\nxPCA = pca.transform(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xPCA[0,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#principalDF = pd.DataFrame(data = xPCA, columns = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10'])\n#principalDF = pd.DataFrame(data = xPCA, columns = ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7'])\nprincipalDF = pd.DataFrame(data = x, columns = features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targetDF = pd.DataFrame(data = dfObj.loc[:, features].values, columns = features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfFinal = pd.concat([principalDF, inputData[['chk']]], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dfData = dfFinal.loc[:, ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10']].values\n#dfData = dfFinal.loc[:, ['P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7']].values\ndfData = dfFinal.loc[:, features].values\ndfLabel = dfFinal.loc[:, 'chk'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HFtrain_data, HFtest_data, HFtrain_label, HFtest_label = train_test_split(dfData, dfLabel, test_size=0.2, random_state=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogisticRegr = LogisticRegression(solver = 'lbfgs')\n#logisticRegr.fit(HFtrain_data, HFtrain_label)\n#logisticRegr.score(HFtest_data, HFtest_label)\nlogisticRegr.fit(dfData, dfLabel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.count_nonzero(logisticRegr.predict(dfObj.loc[:, features].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logisticRegr.predict(dfObj.loc[:, features].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#HFtest_label[0:7]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nclfNN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 8), random_state=0)\n#clf.fit(HFtrain_data, HFtrain_label)\nclfNN.fit(dfData, dfLabel)\n#clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfNN.predict((dfObj.loc[:, features].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\nclfSVM = svm.SVC()\n#clf.fit(HFtrain_data, HFtrain_label)\nclfSVM.fit(dfData, dfLabel)\n#clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clfSVM.predict((dfObj.loc[:, features].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nbagging = BaggingClassifier(KNeighborsClassifier(), max_samples=0.9, max_features=0.9)\n#bagging = bagging.fit(HFtrain_data, HFtrain_label)\n#bagging.score(HFtest_data, HFtest_label)\nbagging = bagging.fit(dfData, dfLabel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bagging.predict((dfObj.loc[:, features].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=150)\nclf.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict((dfObj.loc[:, features].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestCentroid\nclf = NearestCentroid()\nclf.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\nfrom sklearn.pipeline import Pipeline\nnca = NeighborhoodComponentsAnalysis(random_state=0)\nknn = KNeighborsClassifier(n_neighbors=13)\nnca_pipe = Pipeline([('nca', nca), ('knn', knn)])\nnca_pipe.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(nca_pipe.score(HFtest_data, HFtest_label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = tree.DecisionTreeRegressor()\nclf = clf.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(n_estimators=40)\nclf = clf.fit(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nclf = AdaBoostClassifier(n_estimators=100)\nclf = clf.fit(HFtrain_data, HFtrain_label)\nclf.score(HFtest_data, HFtest_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nclf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\nclf.fit(HFtrain_data, HFtrain_label)\nclf.score(HFtrain_data, HFtrain_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testDCM = Path('../input/vinbigdata-chest-xray-abnormalities-detection/train/0032c6091dc8f1b1245fc2f5f45458fa.dicom')\ndcm = testDCM.dcmread()\ndcm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['#e41a1c', '#377eb8','#4daf4a','#984ea3','#ff7f00','#ffff33','#a65628','#f781bf','#999999', '#000000', '#1b9e77', '#d95f02', '#7570b3', '#e7298a']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dcm.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train[train['image_id']=='0032c6091dc8f1b1245fc2f5f45458fa']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = preprocessing.LabelEncoder() # encode rad_id\ntrain['rad_label'] = le.fit_transform(train['rad_id'])\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define model function to be used to fit to the data above:\ndef gauss(x, *p):\n    A, mu, sigma = p\n    return A*np.exp(-(x-mu)**2/(2.*sigma**2))\n# Fucntion to calculate the exponential with constants a and b\ndef expon(x, a, b):\n    return a*np.exp(b*x)\n# Define 2d-Guassian function to fit to the data given:\ndef gauss2d(*p):\n    height, center_x, center_y, width_x, width_y = p\n    width_x = float(width_x)\n    width_y = float(width_y)\n    return lambda x,y: height*np.exp(\n                -(((center_x-x)/width_x)**2+((center_y-y)/width_y)**2)/2)\n# Based on the function above, we need to further define a two-centered Gaussian fucntion\ndef twoCenterGaussion(*p):\n    height1, center_x1, center_y1, width_x1, width_y1, height2, center_x2, center_y2, width_x2, width_y2 = p\n    p1 = np.array(height1, center_x1, center_y1, width_x1, width_y1)\n    p2 = np.array(height2, center_x2, center_y2, width_x2, width_y2)\n    return gauss2d(*p1) + gauss2d(*p2)\n\n# Fitting Gauss\ndef fitgaussian(data, *pa):\n    params = pa\n    errorfunction = lambda p: np.ravel(gaussian(*p)(*np.indices(data.shape)) -\n                                 data)\n    p, success = optimize.leastsq(errorfunction, params)\n    return p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DrawGauss(num):\n    # num is an integer, indicating the positon of classes\n    studyClasses = train[train.class_name == classes[num]]\n    studyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\n    y = studyClasses.boxArea\n    #plt.figure(figsize=(14,6))\n    plt.title(classes[num])\n    plt.hist(y, bins = 200)\n    mean=y.mean()\n    highest=y.max()\n    p0 = [highest, mean, mean]\n    try:\n        hist, bin_edges =  np.histogram(y, bins = 200, density=False)\n        bin_centres = (bin_edges[:-1] + bin_edges[1:])/2\n        coeff, var_matrix = curve_fit(gauss, bin_centres, hist, p0=p0)\n        # Get the fitted curve\n        hist_fit = gauss(bin_centres, *coeff)\n        plt.plot(bin_centres, hist_fit, label='Fitted data', color='red')\n        #print ('Fitted mean = ', coeff[1])\n        #print ('Fitted standard deviation = ', coeff[2])\n    except:\n        print('Mean value = ', mean)\n    imag = plt.show()\n    #return imag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a look at the spatial distribution of the area of boxes for different\n# categories of diseases\ndef boxArea3d(num):\n    sns.set(style = 'darkgrid')\n\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(111, projection = '3d')\n    studyClasses = train[train.class_name == classes[num]]\n    studyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\n    #plt.figure(figsize=(16,16))\n    center = pd.DataFrame()\n    center['center_x'] = studyClasses.apply(center_x, axis = 1)\n    center['center_y'] = studyClasses.apply(center_y, axis = 1)\n    #plt.figure(figsize=(14,6))\n    plt.title(classes[num] + \": 3d\")\n    #plt.scatter(center.center_x, center.center_y)\n    ax.set_xlabel(\"center_x\")\n    ax.set_ylabel(\"center_y\")\n    ax.set_zlabel(\"boxArea\")\n    ax.scatter(center.center_x, center.center_y, studyClasses.boxArea)\n    fig.show()\n    \"\"\"\n    # Let me try plotly to draw interactive graph\n    py.init_notebook_mode(connected=True)\n    studyClasses = train[train.class_name == classes[num]]\n    studyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\n    center = pd.DataFrame()\n    center['center_x'] = studyClasses.apply(center_x, axis = 1)\n    center['center_y'] = studyClasses.apply(center_y, axis = 1)\n    trace = go.Scatter3d(\n        x = center.center_x,\n        y = center.center_y,\n        z = studyClasses.boxArea,\n        mode = 'markers',\n        marker = dict(\n            size = 12,\n            line = dict(\n                color = 'rgba(217, 217, 217, 0.14)',\n                width = 0.5\n            ),\n            opacity = 1\n        ),\n        name = classes[num] + \": 3d\"\n    )\n    data = [trace]\n    layout = go.Layout(\n        margin = dict(\n            l = 0,\n            r = 0,\n            b = 0,\n            t = 0\n        )\n    )\n    fig = go.Figure(data = data, layout = layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 0\nfor row in train.iloc[0:-1, 1]:\n    if row == \"Cardiomegaly\":\n        n += 1\nprint(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[1]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\nx = np.arange(0, n, 1)\ny = studyClasses.boxArea\nplt.figure(figsize=(14,6))\nplt.scatter(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DrawGauss(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 0\nfor row in train.iloc[0:-1, 1]:\n    if row == \"Aortic enlargement\":\n        n += 1\nprint(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyAortic = train[train.class_name == \"Aortic enlargement\"]\nstudyAortic['boxArea'] = studyAortic.apply(get_area, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyAortic.boxArea","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(0, 7162, 1)\ny = studyAortic.boxArea\nplt.figure(figsize=(14,6))\nplt.scatter(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 0\nfor row in train.iloc[0:-1, 1]:\n    if row == 'Pleural thickening':\n        n += 1\nprint(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyPleural_thickening = train[train.class_name == \"Pleural thickening\"]\nstudyPleural_thickening['boxArea'] = studyPleural_thickening.apply(get_area, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(0, n, 1)\ny = studyPleural_thickening.boxArea\nplt.figure(figsize=(14,6))\nplt.scatter(x, y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[2]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\ncenter = pd.DataFrame()\ncenter['center_x'] = studyClasses.apply(center_x, axis = 1)\ncenter['center_y'] = studyClasses.apply(center_y, axis = 1)\nplt.figure(figsize=(14,6))\nplt.scatter(center.center_x, center.center_y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[3]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[4]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[5]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[6]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[7]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[8]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[9]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw_center(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[10]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[11]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#draw_center(11)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[12]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"draw_center(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"studyClasses = train[train.class_name == classes[13]]\nstudyClasses['boxArea'] = studyClasses.apply(get_area, axis = 1)\ny = studyClasses.boxArea\nDrawGauss(13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following codes are modified from notebook: [EDA-VinBigData Chest X-ray Abnormalities](https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities)"},{"metadata":{"trusted":true},"cell_type":"code","source":"FoundSth = train[train['class_name'] != 'No finding']\n\nimgs = []\nimg_ids = FoundSth['image_id'].values\nclass_ids = FoundSth['class_id'].unique()\n\n# map label_id to specify color\nlabel2color = {class_id:[randint(0,255) for i in range(3)] for class_id in class_ids}\nthickness = 3\nscale = 5\n\nfor i in range(1):\n    img_id = random.choice(img_ids)\n    #print(img_id)\n    img_path = f'{dataset_dir}/train/{img_id}.dicom'\n    img = dicom2array(path=img_path)\n    #print(\"Before resize: \")\n    #img\n    img = cv2.resize(img, None, fx=1/scale, fy=1/scale)\n    #print(\"After resize: \")\n    #img\n    img = np.stack([img, img, img], axis=-1)\n    \n    boxes = FoundSth.loc[FoundSth['image_id'] == img_id, ['x_min', 'y_min', 'x_max', 'y_max']].values/scale\n    labels = FoundSth.loc[FoundSth['image_id'] == img_id, ['class_id']].values.squeeze()\n    #print(boxes)\n    for label_id, box in zip(labels, boxes):\n        color = label2color[label_id]\n        img = cv2.rectangle(\n            img,\n            (int(box[0]), int(box[1])),\n            (int(box[2]), int(box[3])),\n            color, thickness\n    )\n    img = cv2.resize(img, (500,500))\n    imgs.append(img)\n    \nplot_imgs(imgs, cmap=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## [Mahotas – Cropping Image](https://www.geeksforgeeks.org/mahotas-cropping-image/?ref=rp)\n\n[Mahotas Features](https://mahotas.readthedocs.io/en/latest/mahotas-features.html)\n\n[数据科学与机器学习](https://mlhowto.readthedocs.io/en/latest/opencv.html)"},{"metadata":{"trusted":true},"cell_type":"code","source":"HFs = ['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13']\n#for newcol in HFs:\n#    FoundSth[newcol] = 0\nif 'HF1' not in FoundSth.columns:\n    for newcol in HFs:\n        FoundSth[newcol] = 0\n#FoundSth.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get Haralick Features\ndef getHF(img_ids):  \n    imgT = []\n    HF = []\n    img_path = f'{dataset_dir}/train/{img_id}.dicom'\n    imgT = dicom2array(path=img_path)\n    imgT = np.stack([imgT, imgT, imgT], axis=-1)\n    \n    boxes = FoundSth.loc[FoundSth['image_id'] == img_id, ['x_min', 'y_min', 'x_max', 'y_max']].values\n    for box in boxes:\n        img = imgT[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n        meanValue = mh.features.haralick(img).mean(0)\n        HF.append(meanValue)\n    return HF                             ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FoundSth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get Haralick Features for a single box\n\"\"\"\ndef getHF_each_box(index):\n    imgT = []\n    HF = []\n    img_id = FoundSth.loc[FoundSth.index == index, 'image_id'].values\n    img_path = f'{dataset_dir}/train/{img_id[0]}.dicom'\n    imgT = dicom2array(path=img_path)\n    imgT = np.stack([imgT, imgT, imgT], axis=-1)\n    #temp = train[train.index == index]\n    box = FoundSth.loc[FoundSth.index == index, ['x_min', 'y_min', 'x_max', 'y_max']].values\n    img = imgT[int(box[0,1]):int(box[0,3]), int(box[0,0]):int(box[0,2])]\n    meanValue = mh.features.haralick(img).mean(0)\n    HF.append(meanValue)\n    return HF\n\"\"\"\n#HF\nget = FoundSth.loc[6016*3:6016*4]\ndef getHF_each_box(row):\n    imgT = []\n    #print(row['image_id'])\n    img_id = str(row['image_id'])\n    img_path = f'{dataset_dir}/train/{img_id}.dicom'\n    imgT = dicom2array(path=img_path)\n    imgT = np.stack([imgT, imgT, imgT], axis=-1)\n    box = row.loc[['x_min', 'y_min', 'x_max', 'y_max']].values\n    #print(box.shape)\n    img = imgT[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n    meanValue = mh.features.haralick(img).mean(0)\n    get.loc[row.name,['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13']] = meanValue\n    #print(type(meanValue[0]))\n    #row.descript\n    #get.iloc[row.index:row.index,'HF1'] = meanValue[0]\n    #HF.append(meanValue)\n    #return HF\n    #return meanValue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# The following is a code transformed into markdown\n\"\"\"\nn = 0\nfor i, row in FoundSth.iterrows():\n    if n < 2:\n        row.apply(getHF_each_box)\n        #print(str(row['image_id']))\n    n += 1\n\"\"\"\n#df = pd.DataFrame(columns=['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13'])\n#df = []\n#get = FoundSth.loc[0:6]\n#get = FoundSth.apply(getHF_each_box, axis = 1)\nget.apply(getHF_each_box, axis = 1)\nget.to_csv('FoundSthWithHF.csv')\n#df\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following is a code transformed into markdown\n\"\"\"\nn = 0\nfor i, row in FoundSth.iterrows():\n    if n < 2:\n        row.apply(getHF_each_box)\n        #print(str(row['image_id']))\n    n += 1\n\"\"\"\n#df = pd.DataFrame(columns=['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13'])\n#df = []\n#get = FoundSth.loc[0:6]\n#get = FoundSth.apply(getHF_each_box, axis = 1)\nget.apply(getHF_each_box, axis = 1)\nget.to_csv('FoundSthWithHF.csv')\n#df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df.index:\n    print(df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.DataFrame(df[2], columns = ['HF1', 'HF2','HF3','HF4','HF5','HF6','HF7','HF8','HF9', 'HF10', 'HF11', 'HF12', 'HF13'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get.at[2, \"HF1\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FoundSth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import gray, imshow, show\n\n#img = img[100:300,100:300]\n#imshow(img)\n#show()\n#h_feature = mh.features.haralick(img)\n#print(\"Haralick Features\")\n#imshow(h_feature)\n#show()\nimgT = dicom2array(path=img_path)\n#imgT = cv2.resize(imgT, None, fx=1/scale, fy=1/scale)\nimgT = np.stack([imgT, imgT, imgT], axis=-1)\nn = 0\n\"\"\"\nfor box in boxes:\n    n += 1\n    if n == 1:\n        print(box)i\n        img = img[int(box[0]):int(box[2]), int(box[1]):int(box[3])]\n        imshow(img)\n        show()\n        break\n\"\"\"\nfor box in boxes:\n    #print(box)\n    img = imgT[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n    meanValue = mh.features.haralick(img).mean(0)\n    #print(meanValue)\n    # After repeatedly try, I figure out the line above is correct, so I realize y should\n    # go in front of x.\n    #imshow(img)\n    #show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#getHF(img_ids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Set up a new dataset containing the HFs without images. This step is only for the training purpose right now."},{"metadata":{"trusted":true},"cell_type":"code","source":"#train[train['image_id'] == img_id]\n#classes[1]\ncheck_single_disease = train.loc[(train['image_id'] == img_id) & (train['class_name'] == classes[5])]\n#train.describe\ntrain[train.index == 58645]\n#check_single_disease","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from joblib import Parallel, delayed\nfrom multiprocessing import cpu_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def updateFoundSth():\n#    for i, row in FoundSth.iterrows():\n#    #print(f\"{i}\")\n#        indx = int(f\"{i}\")\n#        ret = getHF_each_box(indx)[0]\n#        n = 0\n#        for HF in HFs:\n#            FoundSth.loc[FoundSth.index == indx, HF] = ret[n]\n#            n += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def updateFoundSth(i):\n    #print(f\"{i}\")\n    indx = int(f\"{i}\")\n    ret = getHF_each_box(indx)[0]\n    n = 0\n    for HF in HFs:\n        FoundSth.loc[FoundSth.index == indx, HF] = ret[n]\n        n += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Parallel(n_jobs = int(cpu_count()), prefer = 'processes')(\n#    delayed(getHF_each_box)(i)[0]\n#    for i in FoundSth.index\n#)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FoundSth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.techbeamers.com/python-glob/\n#The following code is used to generate DataFrame collectInfo\ncollectInfo = pd.DataFrame(columns = ['image_id', 'Health'])\nfor dico in glob.glob(f\"{dataset_dir}/test/*.dicom\"):\n    str = dico.split(\"/\")\n    filename = str[-1].split(\".\")\n    data = [{'image_id': filename[0], 'Health':True}]\n    collectInfo = collectInfo.append(data,ignore_index=True,sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FoundSth.to_csv('FoundSthWithHF.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}